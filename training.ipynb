{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-03-21T17:16:24.030097Z","iopub.status.busy":"2021-03-21T17:16:24.029326Z","iopub.status.idle":"2021-03-21T17:16:26.068084Z","shell.execute_reply":"2021-03-21T17:16:26.066980Z"},"papermill":{"duration":2.054247,"end_time":"2021-03-21T17:16:26.068338","exception":false,"start_time":"2021-03-21T17:16:24.014091","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"import os\nimport time\nimport gc\nimport cv2 as cv\nimport numpy as np\nimport torch\nimport torch.nn as nn","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:26.471857Z","iopub.status.busy":"2021-03-21T17:16:26.470654Z","iopub.status.idle":"2021-03-21T17:16:26.475345Z","shell.execute_reply":"2021-03-21T17:16:26.476342Z"},"papermill":{"duration":0.397924,"end_time":"2021-03-21T17:16:26.476643","exception":false,"start_time":"2021-03-21T17:16:26.078719","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"# Device configuration\nif torch.cuda.is_available():\n    print(\"Device Use: GPU\")\n    device = torch.device(\"cuda\")\nelse :\n    print(\"Device Use: CPU\")\n    device = torch.device(\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:26.504786Z","iopub.status.busy":"2021-03-21T17:16:26.502075Z","iopub.status.idle":"2021-03-21T17:16:26.505524Z","shell.execute_reply":"2021-03-21T17:16:26.506081Z"},"papermill":{"duration":0.018487,"end_time":"2021-03-21T17:16:26.506226","exception":false,"start_time":"2021-03-21T17:16:26.487739","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"# Hyper-parameters \nnum_epochs = 5\nbatch_size = 10\nlearning_rate = 0.001\nmomentum = 0.005","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:26.530023Z","iopub.status.busy":"2021-03-21T17:16:26.529291Z","iopub.status.idle":"2021-03-21T17:16:26.545391Z","shell.execute_reply":"2021-03-21T17:16:26.545935Z"},"papermill":{"duration":0.030649,"end_time":"2021-03-21T17:16:26.546100","exception":false,"start_time":"2021-03-21T17:16:26.515451","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"data_path = \"../input/vr-project-data/dataset\"\ncategories = os.listdir(data_path)\nlabels = [i for i in range(len(categories))]\nlabel_dict = dict(zip(categories,labels))\nprint(label_dict)\nprint(categories)\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:26.574333Z","iopub.status.busy":"2021-03-21T17:16:26.573628Z","iopub.status.idle":"2021-03-21T17:16:42.059969Z","shell.execute_reply":"2021-03-21T17:16:42.058735Z"},"papermill":{"duration":15.504112,"end_time":"2021-03-21T17:16:42.060135","exception":false,"start_time":"2021-03-21T17:16:26.556023","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"img_size=100\ndata=[]\ntarget=[]\n\nfor category in categories:\n    \n    folder_path=os.path.join(data_path,category)\n    img_names=os.listdir(folder_path)\n        \n    for img_name in img_names:\n        \n        img_path = os.path.join(folder_path,img_name)\n        img = cv.imread(img_path)\n        \n        #Coverting the image into gray scale\n        gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)            \n\n        #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset\n        resized=cv.resize(gray,(img_size,img_size),interpolation = cv.INTER_CUBIC)            \n\n        #appending the image and the label(categorized) into the list (dataset)\n        data.append(resized)\n        target.append(label_dict[category])","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:42.092775Z","iopub.status.busy":"2021-03-21T17:16:42.091431Z","iopub.status.idle":"2021-03-21T17:16:42.263437Z","shell.execute_reply":"2021-03-21T17:16:42.262604Z"},"papermill":{"duration":0.193048,"end_time":"2021-03-21T17:16:42.263657","exception":false,"start_time":"2021-03-21T17:16:42.070609","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"data=np.array(data).astype(np.float32)\ndata=np.array(data)/255.0\ndata=np.reshape(data,(data.shape[0],1,img_size,img_size))\ntarget=np.array(target).astype(np.int)\n\nimages = torch.from_numpy(data)\nlabel = torch.from_numpy(target)\n\nprint(images.shape)\nprint(label.shape)\n\n# createing data set\ntotal = torch.utils.data.TensorDataset(images,label)\ntrain = torch.utils.data.DataLoader(total, batch_size=batch_size, shuffle=True)\n\ndataiter = iter(train)\nimages,label = dataiter.next()\nprint(images.shape)\nprint(label.shape)\n\ndel data\ndel target\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:42.290797Z","iopub.status.busy":"2021-03-21T17:16:42.289923Z","iopub.status.idle":"2021-03-21T17:16:42.293602Z","shell.execute_reply":"2021-03-21T17:16:42.294132Z"},"papermill":{"duration":0.01937,"end_time":"2021-03-21T17:16:42.294307","exception":false,"start_time":"2021-03-21T17:16:42.274937","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"# conv1 = nn.Conv2d(1,100,3)\n# ac = nn.ReLU()\n# pool = nn.MaxPool2d(2)\n\n# conv2 = nn.Conv2d(100,200,3)\n# ac = nn.ReLU()\n# pool = nn.MaxPool2d(2)\n\n# # x = x.view(x.size(0), -1)\n# drop = nn.Dropout(0.2)\n\n# print(\"Original: \", images.shape)\n\n# x=conv1(images)\n# print(\"conv1: \",x.shape)\n\n# x=pool(x)\n# print(\"Pool: \",x.shape)\n\n# x=conv2(x)\n# print(\"conv2: \",x.shape)\n\n# x=pool(x)\n# print(\"Pool: \",x.shape)\n\n# x=drop(x)\n# print(\"Drop: \",x.shape)\n\n# # x=pool(x)\n# # print(\"Pool: \",x.shape)\n\n# fc1 = nn.Linear(32 * 3 * 3, 50)\n# fc2 = nn.Linear(50, 2)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:42.330707Z","iopub.status.busy":"2021-03-21T17:16:42.329749Z","iopub.status.idle":"2021-03-21T17:16:48.491630Z","shell.execute_reply":"2021-03-21T17:16:48.490444Z"},"papermill":{"duration":6.186942,"end_time":"2021-03-21T17:16:48.491810","exception":false,"start_time":"2021-03-21T17:16:42.304868","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"class ConvNet(nn.Module):\n\n    def __init__(self):\n        super(ConvNet, self).__init__()        \n        \n        self.ac = nn.ReLU()\n        self.pool = nn.MaxPool2d(2)\n        \n        self.conv1 = nn.Conv2d(1,100,3)\n        self.conv2 = nn.Conv2d(100,200,3)\n        self.drop = nn.Dropout(0.2)\n        \n        self.fc1 = nn.Linear(200*23*23, 50)\n        self.fc2 = nn.Linear(50, 2)\n\n    def forward(self, x):\n        \n        #cnn layer 1\n        x = self.conv1(x)\n        x = self.ac(x)\n        x = self.pool(x)\n        \n        #cnn layer 2\n        x = self.conv2(x)\n        x = self.ac(x)\n        x = self.pool(x)\n        \n        #flatten\n        x = x.view(-1,200*23*23)\n        \n        #drop\n        x = self.drop(x)\n        \n        #dense\n        x = self.fc1(x)\n        \n        #dense\n        x = self.fc2(x)\n        return x\n\nmodel = ConvNet().to(device)\ncriterion =  nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate ,momentum = momentum)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:48.522890Z","iopub.status.busy":"2021-03-21T17:16:48.522219Z","iopub.status.idle":"2021-03-21T17:16:54.630924Z","shell.execute_reply":"2021-03-21T17:16:54.631670Z"},"papermill":{"duration":6.128773,"end_time":"2021-03-21T17:16:54.631959","exception":false,"start_time":"2021-03-21T17:16:48.503186","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"start_time = time.time()\n\nfor epoch in range(num_epochs):  \n    tot_loss=0.0\n    for i, (images, labels) in enumerate(train):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        tot_loss+=loss.item()\n    \n    print (\"Epoch: \", epoch+1, \" total Loss: \", tot_loss , \"Average Loss : \", tot_loss/len(train) )\n\nend_time = time.time()            \nprint('Finished Training')\nprint('Time taken:',end_time - start_time)\n\nprint(model.eval())\nPATH = './model.pth'\ntorch.save(model, PATH)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-21T17:16:54.663349Z","iopub.status.busy":"2021-03-21T17:16:54.662370Z","iopub.status.idle":"2021-03-21T17:16:54.688747Z","shell.execute_reply":"2021-03-21T17:16:54.689569Z"},"papermill":{"duration":0.043942,"end_time":"2021-03-21T17:16:54.689823","exception":false,"start_time":"2021-03-21T17:16:54.645881","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"mm = torch.load(PATH)\nprint(mm.eval())\nprint(\"Model Saved!!\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.013145,"end_time":"2021-03-21T17:16:54.716982","exception":false,"start_time":"2021-03-21T17:16:54.703837","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}